{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions necessary to group the minute level to hours/days\n",
    "def get_first_element(x):\n",
    "    return x.iloc[0]\n",
    "\n",
    "def get_last_element(x):\n",
    "    return x.iloc[len(x)-1]\n",
    "\n",
    "# indicate the indicator as positive when the price is within specified threshold \n",
    "##ranges compared to the open for the long strategy\n",
    "def infer_profit_long_indicator(x,threshold=1.02):\n",
    "    if x['next_1high'] >= threshold*x['Open']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def infer_profit_short_indicator(x,threshold=0.98):\n",
    "    if x['next_1low'] <= threshold*x['Open']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# to normalize the prices of \n",
    "def zscore_func_improved(x,window_size=50):\n",
    "    rolling_mean=x.rolling(window=window_size).mean().bfill()\n",
    "    rolling_std = x.rolling(window=window_size).std().bfill()\n",
    "    return (x-rolling_mean)/rolling_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing FCPO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pre-process the excel file containing 2007-2017 data\n",
    "\n",
    "# fcpo_data_10yrs_raw=pd.read_excel('data/FCPO.xlsx')\n",
    "\n",
    "# fcpo_data_10yrs=fcpo_data_10yrs_raw.drop(columns=['General'])\n",
    "# fcpo_data_10yrs=fcpo_data_10yrs.rename(columns={'High ':'High','Volume ':'Volume'})\n",
    "\n",
    "# fcpo_data_10yrs['Date']=fcpo_data_10yrs['Date'].apply(lambda x:str(x))\n",
    "# fcpo_data_10yrs['Hour']=fcpo_data_10yrs['Time'].apply(lambda x:str(x)[0:2])\n",
    "\n",
    "# fcpo_data_10yrs_daily=fcpo_data_10yrs.groupby(['Date'],as_index=False).agg({'Open':lambda x: get_first_element(x),'Close': lambda x:get_last_element(x),\n",
    "#                               'High':lambda x:np.max(x),'Low':lambda x:np.min(x),'Volume':'sum'})\n",
    "# fcpo_data_10yrs_daily=fcpo_data_10yrs_daily.set_index(pd.to_datetime(fcpo_data_10yrs_daily['Date']))\n",
    "# # handle the data difference with the 2014-2018 data\n",
    "# fcpo_data_10yrs_daily[['Open','Close','High','Low']]=fcpo_data_10yrs_daily[['Open','Close','High','Low']].applymap(lambda x: x-178)\n",
    "# fcpo_data_2009_2013_daily=fcpo_data_10yrs_daily['2009-01-01':'2014-01-01']\n",
    "\n",
    "# fcpo_data_2009_2013_daily=fcpo_data_2009_2013_daily.drop(columns=['Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Back Adjusted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process the data from 2014-2018 csv file\n",
    "fcpo_data=pd.read_csv('data/FCPO_2007-2017_backadjusted.csv')\n",
    "\n",
    "#remove identity placeholder columns\n",
    "fcpo_data=fcpo_data[fcpo_data['Time']!=1805]\n",
    "\n",
    "#convert the date time values to string and derive the hour field\n",
    "fcpo_data['Date']=fcpo_data['Date'].apply(lambda x:str(x))\n",
    "fcpo_data['Hour']=fcpo_data['Time'].apply(lambda x:str(x)[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily and hourly data frames\n",
    "fcpo_data_daily=fcpo_data.groupby(['Date'],as_index=False).agg({'Open':lambda x: get_first_element(x),'Close': lambda x:get_last_element(x),\n",
    "                              'High':lambda x:np.max(x),'Low':lambda x:np.min(x),'Volume':'sum'})\n",
    "\n",
    "fcpo_data_daily=fcpo_data_daily.set_index(pd.to_datetime(fcpo_data_daily['Date']))\n",
    "\n",
    "fcpo_data_daily=fcpo_data_daily.drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcpo_data_daily=fcpo_data_2014_2018_daily.copy()\n",
    "## infer the profit indicators based on the future closing/high or low  prices\n",
    "# shift the output of next day into the daily data frame\n",
    "fcpo_data_daily=fcpo_data_daily.assign(next_1close=fcpo_data_daily['Close'].shift(-1),\n",
    "                      next_1high=fcpo_data_daily['High'].shift(-1),\n",
    "                      next_1low=fcpo_data_daily['Low'].shift(-1),\n",
    "                      next_1open=fcpo_data_daily['Open'].shift(-1),\n",
    "                      prev_1close=fcpo_data_daily['Close'].shift(1),                 \n",
    "                      )\n",
    "\n",
    "fcpo_data_daily=fcpo_data_daily.assign(next_open_change_pct=(fcpo_data_daily['Open']/fcpo_data_daily['prev_1close'])*100-100,\n",
    "                            lprofit_ind=fcpo_data_daily.apply(lambda x:infer_profit_long_indicator(x,1.02),axis=1),\n",
    "                            sprofit_ind=fcpo_data_daily.apply(lambda x:infer_profit_short_indicator(x,0.98),axis=1))\n",
    "\n",
    "fcpo_data_daily['next_open_change_pct']=fcpo_data_daily['next_open_change_pct'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcpo_data_hourly=fcpo_data.groupby(['Date','Hour'],as_index=False).agg({'Open':lambda x: get_first_element(x),'Close': lambda x:get_last_element(x),\n",
    "                              'High':lambda x:np.max(x),'Low':lambda x:np.min(x),'Volume':'sum'})\n",
    "\n",
    "fcpo_data_hourly=fcpo_data_hourly.set_index(pd.to_datetime(fcpo_data_hourly['Date']+'-'+fcpo_data_hourly['Hour']))\n",
    "fcpo_data_hourly=fcpo_data_hourly.drop(columns=['Date','Hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcpo_data_hourly=fcpo_data_2014_2018_hourly.copy()\n",
    "## infer the profit indicators based on the future closing prices\n",
    "# shift the output of next 3 time periods into the daily data frame\n",
    "fcpo_data_hourly=fcpo_data_hourly.assign(next_1close=fcpo_data_hourly['Close'].shift(-1),\n",
    "                      next_1high=fcpo_data_hourly['High'].shift(-1),\n",
    "                      next_1low=fcpo_data_hourly['Low'].shift(-1),\n",
    "                      next_1open=fcpo_data_hourly['Open'].shift(-1))\n",
    "\n",
    "fcpo_data_hourly=fcpo_data_hourly.assign(lprofit_ind=fcpo_data_hourly.apply(lambda x:infer_profit_long_indicator(x,1.01),axis=1),\n",
    "                                       sprofit_ind=fcpo_data_hourly.apply(lambda x:infer_profit_short_indicator(x,0.99),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dalian Palm oil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "palmoil_data=pd.read_excel('data/Dalian Palm Olein 1 Mins_updated.xlsx',skiprows=3)\n",
    "palmoil_data=palmoil_data.drop(0)\n",
    "\n",
    "palmoil_data['Date']=palmoil_data['Dates'].dt.date\n",
    "palmoil_data['Hour']=palmoil_data['Dates'].dt.hour\n",
    "\n",
    "# Compute daily and hourly data frames\n",
    "palmoil_data_daily=palmoil_data.groupby(['Date'],as_index=False).agg({'Open':lambda x: get_first_element(x),'Close': lambda x:get_last_element(x),\n",
    "                              'High':lambda x:np.max(x),'Low':lambda x:np.min(x),'Volume':'sum'})\n",
    "palmoil_data_hourly=palmoil_data.groupby(['Date','Hour'],as_index=False).agg({'Open':lambda x: get_first_element(x),'Close': lambda x:get_last_element(x),\n",
    "                              'High':lambda x:np.max(x),'Low':lambda x:np.min(x),'Volume':'sum'})\n",
    "\n",
    "palmoil_data_daily=palmoil_data_daily.set_index(pd.to_datetime(palmoil_data_daily['Date']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the Processed data in HDF5 format for pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->date,key->block1_values] [items->['Date']]\n",
      "\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "hdf_store=pd.HDFStore('processed_dta.h5')\n",
    "\n",
    "hdf_store.put('fcpo_data_daily',fcpo_data_daily)\n",
    "\n",
    "hdf_store.put('fcpo_data_hourly',fcpo_data_hourly)\n",
    "\n",
    "hdf_store.put('palmoil_data_daily',palmoil_data_daily)\n",
    "\n",
    "hdf_store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
