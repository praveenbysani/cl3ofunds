{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions necessary to group the minute level to hours/days\n",
    "def get_first_element(x):\n",
    "    return x.iloc[0]\n",
    "\n",
    "def get_last_element(x):\n",
    "    return x.iloc[len(x)-1]\n",
    "\n",
    "# indicate the indicator as positive when the price is within specified threshold \n",
    "##ranges compared to the open for the long strategy\n",
    "def infer_profit_long_indicator(x,threshold=1.02):\n",
    "    #max_close=max(x['next_1close'],x['next_2close'],x['next_3close'])\n",
    "    max_close=x['next_1high']\n",
    "    if max_close >= threshold*x['Open']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def infer_profit_short_indicator(x,threshold=0.98):\n",
    "    if x['next_1low'] <= threshold*x['Open']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# to normalize the prices of \n",
    "def zscore_func_improved(x,window_size=50):\n",
    "    rolling_mean=x.rolling(window=window_size).mean().bfill()\n",
    "    rolling_std = x.rolling(window=window_size).std().bfill()\n",
    "    return (x-rolling_mean)/rolling_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dalian Palm oil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "palmoil_data=pd.read_excel('data/Dalian Palm Olein 1 Mins_updated.xlsx',skiprows=3)\n",
    "palmoil_data=palmoil_data.drop(0)\n",
    "\n",
    "palmoil_data['Date']=palmoil_data['Dates'].dt.date\n",
    "palmoil_data['Hour']=palmoil_data['Dates'].dt.hour\n",
    "\n",
    "# Compute daily and hourly data frames\n",
    "palmoil_data_daily=palmoil_data.groupby(['Date'],as_index=False).agg({'Open':lambda x: get_first_element(x),'Close': lambda x:get_last_element(x),\n",
    "                              'High':lambda x:np.max(x),'Low':lambda x:np.min(x),'Volume':'sum'})\n",
    "palmoil_data_hourly=palmoil_data.groupby(['Date','Hour'],as_index=False).agg({'Open':lambda x: get_first_element(x),'Close': lambda x:get_last_element(x),\n",
    "                              'High':lambda x:np.max(x),'Low':lambda x:np.min(x),'Volume':'sum'})\n",
    "\n",
    "palmoil_data_daily=palmoil_data_daily.set_index(pd.to_datetime(palmoil_data_daily['Date']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing FCPO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcpo_data=pd.read_csv('data/FCPO_2014_2018_0719.csv')\n",
    "\n",
    "#remove identity placeholder columns\n",
    "fcpo_data=fcpo_data[fcpo_data['Time']!=1805]\n",
    "\n",
    "#convert the date time values to string and derive the hour field\n",
    "fcpo_data['Date']=fcpo_data['Date'].apply(lambda x:str(x))\n",
    "fcpo_data['Hour']=fcpo_data['Time'].apply(lambda x:str(x)[0:2])\n",
    "\n",
    "# Compute daily and hourly data frames\n",
    "fcpo_data_daily=fcpo_data.groupby(['Date'],as_index=False).agg({'Open':lambda x: get_first_element(x),'Close': lambda x:get_last_element(x),\n",
    "                              'High':lambda x:np.max(x),'Low':lambda x:np.min(x),'Volume':'sum'})\n",
    "fcpo_data_hourly=fcpo_data.groupby(['Date','Hour'],as_index=False).agg({'Open':lambda x: get_first_element(x),'Close': lambda x:get_last_element(x),\n",
    "                              'High':lambda x:np.max(x),'Low':lambda x:np.min(x),'Volume':'sum'})\n",
    "\n",
    "fcpo_data_daily=fcpo_data_daily.set_index(pd.to_datetime(fcpo_data_daily['Date']))\n",
    "fcpo_data_hourly=fcpo_data_hourly.set_index(pd.to_datetime(fcpo_data_hourly['Date']+'-'+fcpo_data_hourly['Hour']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## infer the profit indicators based on the future closing/high or low  prices\n",
    "# shift the output of next day into the daily data frame\n",
    "fcpo_data_daily=fcpo_data_daily.assign(next_1close=fcpo_data_daily['Close'].shift(-1),\n",
    "                      next_1high=fcpo_data_daily['High'].shift(-1),\n",
    "                      next_1low=fcpo_data_daily['Low'].shift(-1),\n",
    "                      next_1open=fcpo_data_daily['Open'].shift(-1),\n",
    "                      prev_1close=fcpo_data_daily['Close'].shift(1),                 \n",
    "                      )\n",
    "\n",
    "fcpo_data_daily=fcpo_data_daily.assign(next_open_change_pct=(fcpo_data_daily['Open']/fcpo_data_daily['prev_1close'])*100-100,\n",
    "                            lprofit_ind=fcpo_data_daily.apply(lambda x:infer_profit_long_indicator(x),axis=1),\n",
    "                            sprofit_ind=fcpo_data_daily.apply(lambda x:infer_profit_short_indicator(x),axis=1))\n",
    "\n",
    "fcpo_data_daily['next_open_change_pct']=fcpo_data_daily['next_open_change_pct'].bfill()\n",
    "fcpo_data_daily=fcpo_data_daily.drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## infer the profit indicators based on the future closing prices\n",
    "# shift the output of next 3 time periods into the daily data frame\n",
    "fcpo_data_hourly=fcpo_data_hourly.assign(next_1close=fcpo_data_hourly['Close'].shift(-1),\n",
    "                      next_1high=fcpo_data_hourly['High'].shift(-1),\n",
    "                      next_1low=fcpo_data_hourly['Low'].shift(-1),\n",
    "                      next_1open=fcpo_data_hourly['Open'].shift(-1))\n",
    "\n",
    "fcpo_data_hourly=fcpo_data_hourly.assign(lprofit_ind=fcpo_data_hourly.apply(lambda x:infer_profit_long_indicator(x),axis=1),\n",
    "                                       sprofit_ind=fcpo_data_hourly.apply(lambda x:infer_profit_short_indicator(x),axis=1))\n",
    "\n",
    "fcpo_data_hourly=fcpo_data_hourly.drop(columns=['Date','Hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_store=pd.HDFStore('processed_dta.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_store.put('fcpo_data_daily',fcpo_data_daily)\n",
    "\n",
    "hdf_store.put('fcpo_data_hourly',fcpo_data_hourly)\n",
    "\n",
    "hdf_store.put('palmoil_data_daily',palmoil_data_daily)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
